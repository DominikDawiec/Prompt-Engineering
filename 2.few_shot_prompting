## Few-Shot Prompting

### Czym jest Few-Shot Prompting?

**Few-Shot Prompting** to technika, w której model językowy (LLM) otrzymuje w promptcie kilka przykładów, aby lepiej zrozumieć zadanie i poprawnie wygenerować odpowiedź. W przeciwieństwie do Zero-Shot Promptingu, gdzie instrukcje są podawane bez przykładów, w Few-Shot Promptingu przykłady służą jako kontekst, który pomaga modelowi lepiej dopasować odpowiedź do specyficznego zadania.

Few-shot prompting wykorzystuje zdolność modeli LLM do nauki w kontekście (in-context learning), co pozwala im dostosowywać swoje odpowiedzi na podstawie dostarczonych demonstracji.

---

### Jak działa Few-Shot Prompting?

Podstawą Few-Shot Promptingu jest podanie jednego lub więcej przykładów, które ilustrują oczekiwane zachowanie modelu. Na przykładzie zadania użycia nowego słowa w zdaniu:

**Prompt:**
```
A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:  
We were traveling in Africa and we saw these very cute whatpus.

To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
```

**Output:**
```
When we won the game, we all started to farduddle in celebration.
```

W powyższym przykładzie model nauczył się poprawnie używać nowego słowa na podstawie jednego przykładu (tzw. 1-shot).

---

### Przykłady Few-Shot Promptingu

#### Przykład 1: Klasyfikacja sentymentu z losowymi etykietami
**Prompt:**
```
This is awesome! // Negative  
This is bad! // Positive  
Wow that movie was rad! // Positive  
What a horrible show! //  
```

**Output:**
```
Negative
```

Mimo losowych etykiet, model był w stanie poprawnie ocenić ostatni przykład jako negatywny. Pokazuje to, jak formatowanie przykładów wpływa na wynik.

#### Przykład 2: Klasyfikacja z mieszanym formatem
**Prompt:**
```
Positive This is awesome!  
This is bad! Negative  
Wow that movie was rad!  
Positive  
What a horrible show! --  
```

**Output:**
```
Negative
```

Chociaż format promptu był niespójny, model nadal przewidział poprawną etykietę.

---

### Ograniczenia Few-Shot Promptingu

1. **Złożone zadania wymagające wieloetapowego rozumowania:**  
   Few-shot prompting może być niewystarczające w przypadku zadań wymagających wielu kroków rozumowania. Na przykład:

   **Prompt:**
   ```
   The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.  
   A:
   ```

   **Output:**
   ```
   Yes, the odd numbers in this group add up to 107, which is an even number.
   ```

   Wynik jest błędny, co pokazuje, że same demonstracje mogą nie wystarczyć w przypadku zadań wymagających logicznego rozumowania.

2. **Brak możliwości generalizacji:**  
   Model może poprawnie działać tylko w obrębie dostarczonych przykładów, ale trudności pojawiają się przy nowym, nieznanym wzorcu danych.

---

### Jak poprawić Few-Shot Prompting?

W bardziej złożonych zadaniach można połączyć Few-Shot Prompting z zaawansowanymi technikami, takimi jak **Chain-of-Thought Prompting**, które wymusza na modelu rozwiązywanie problemu krok po kroku.

---

### Kiedy używać Few-Shot Promptingu?

- Gdy zadanie jest trudniejsze niż standardowe zero-shot.
- Gdy model wymaga dodatkowego kontekstu w postaci przykładów.
- Do testowania zdolności modelu do nauki w kontekście specyficznego zadania.

Few-Shot Prompting to wszechstronna technika, która często sprawdza się w zadaniach wymagających umiarkowanego stopnia zrozumienia. W przypadku bardziej złożonych problemów warto eksperymentować z innymi metodami, np. wspomnianym Chain-of-Thought.
